{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4768d037-395b-4181-83f5-a6938d09bd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch # Importing PyTorch for deep learning tasks\n",
    "import torch.nn as nn # Importing neural network module from PyTorch\n",
    "import torch.optim as optim # Importing optimization algorithms from PyTorch\n",
    "from torch.utils.data import DataLoader, Dataset # Importing DataLoader and Dataset classes for handling data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random #\n",
    "import nltk # Importing Natural Language Toolkit for text processing\n",
    "import pickle # Importing pickle for saving and loading Python objects\n",
    "from nltk.corpus import wordnet # Importing WordNet corpus from NLTK\n",
    "from sklearn.preprocessing import LabelEncoder # Importing LabelEncoder for encoding labels\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict # Importing defaultdict for creating dictionaries with default values\n",
    "import streamlit as st \n",
    "import re # Importing regular expressions for text processing\n",
    "from collections import Counter # Importing Counter for counting hashable objects\n",
    "\n",
    "nltk.download('wordnet') # Downloading WordNet corpus for NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c365b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100        # Maximum length of input sequences\n",
    "BATCH_SIZE = 32      # Batch size for training\n",
    "EPOCHS = 2           # Number of training epochs\n",
    "EMBED_DIM = 128      # Dimension of word embeddings\n",
    "HIDDEN_DIM = 64      # Dimension of LSTM hidden layers\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Hardware selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62f298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTMWithAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, _ = self.lstm(embedded)\n",
    "        attn_weights = torch.softmax(self.attention(outputs).squeeze(-1), dim=1)\n",
    "        context = torch.sum(outputs * attn_weights.unsqueeze(-1), dim=1)\n",
    "        return self.fc(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73acae23",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Key Features:**\n",
    "- **Embedding Layer:** Converts word indices to dense vectors.\n",
    "- **Bidirectional LSTM:** Captures context from both directions in the sequence.\n",
    "- **Attention Mechanism:** Learns to focus on the most relevant words for emotion detection.\n",
    "- **Fully Connected Layer:** Outputs class scores for each emotion.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. **Training and Evaluation**\n",
    "\n",
    "- **Training Loop:**  \n",
    "  The `train` function performs forward and backward passes, updating model weights and tracking loss.\n",
    "\n",
    "- **Evaluation:**  \n",
    "  The `evaluate` function computes predictions on the validation set and prints a detailed classification report (precision, recall, F1-score) for each emotion class.\n",
    "\n",
    "- **Epochs:**  \n",
    "  The model is trained for the specified number of epochs, with performance metrics displayed after each epoch.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. **Saving Model and Artifacts**\n",
    "\n",
    "After training, the following artifacts are saved for deployment:\n",
    "\n",
    "- **Model Weights:** bilstm_model.pt\n",
    "- **Vocabulary:** vocab.pkl\n",
    "- **Label Encoder:** label_encoder.pkl\n",
    "\n",
    "These files are essential for inference and integration with applications such as Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. **Integration and Deployment**\n",
    "\n",
    "- The saved model and assets can be loaded in a Streamlit app (app.py or new.py) for real-time emotion detection and recommendations.\n",
    "- The modular design allows easy extension to other NLP tasks or integration with external APIs.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. **Best Practices and Recommendations**\n",
    "\n",
    "- **Data Quality:** Ensure cleaned_data.csv is properly preprocessed for optimal model performance.\n",
    "- **Hyperparameter Tuning:** Experiment with `EMBED_DIM`, `HIDDEN_DIM`, and `EPOCHS` for best results.\n",
    "- **Model Interpretability:** The attention mechanism provides insights into which words influence predictions.\n",
    "- **Scalability:** The script is designed to handle large datasets efficiently using PyTorch’s DataLoader.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. **Conclusion**\n",
    "\n",
    "This script forms the backbone of the Vibe Bot’s emotion classification engine. It demonstrates best practices in NLP preprocessing, deep learning model construction, and artifact management for deployment. The approach is robust, scalable, and ready for integration into production systems.\n",
    "\n",
    "---\n",
    "\n",
    "**For further details or live demonstrations, refer to the Streamlit application and associated deployment scripts in the project directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a437b1d0-1ace-4505-b407-4bbf70b55dba",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cleaned_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m DEVICE = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ========== DATA LOADING ========== #\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcleaned_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure this has 'text' and 'label'\u001b[39;00m\n\u001b[32m     11\u001b[39m le = LabelEncoder() \u001b[38;5;66;03m#   LabelEncoder to convert string labels to integers\u001b[39;00m\n\u001b[32m     12\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m'\u001b[39m] = le.fit_transform(df[\u001b[33m'\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;66;03m# Encode the 'emotion' column\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'cleaned_data.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========== CONFIG ========== #\n",
    "MAX_LEN = 100 # Maximum length of input sequences\n",
    "BATCH_SIZE = 32 # Batch size for training\n",
    "EPOCHS = 2 # Number of epochs for training\n",
    "EMBED_DIM = 128 # Dimension of word embeddings\n",
    "HIDDEN_DIM = 64 # Dimension of hidden layers in LSTM\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== DATA LOADING ========== #\n",
    "df = pd.read_csv(\"cleaned_data.csv\")  # Ensure this has 'text' and 'label'\n",
    "le = LabelEncoder() #   LabelEncoder to convert string labels to integers\n",
    "df['emotion'] = le.fit_transform(df['emotion']) # Encode the 'emotion' column\n",
    "\n",
    "# Train-validation split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['cleaned_text'], df['emotion'], test_size=0.2, stratify=df['emotion'], random_state=42)\n",
    "\n",
    "# Build vocab without torchtext\n",
    "vocab_dict = {'<pad>': 0, '<unk>': 1} # Initialize vocabulary dictionary with padding and unknown tokens\n",
    "index = 2 # Start indexing from 2 to reserve 0 for padding and 1 for unknown\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower()) # Tokenize text into words, converting to lowercase\n",
    "\n",
    "for text in train_texts:\n",
    "    for token in tokenize(text):\n",
    "        if token not in vocab_dict:\n",
    "            vocab_dict[token] = index\n",
    "            index += 1\n",
    "\n",
    "# Text to indices\n",
    "def text_to_sequence(text):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [vocab_dict.get(token, vocab_dict['<unk>']) for token in tokens[:MAX_LEN]]\n",
    "    padded = ids + [vocab_dict['<pad>']] * (MAX_LEN - len(ids))\n",
    "    return padded\n",
    "\n",
    "X_train = torch.tensor([text_to_sequence(text) for text in train_texts]) # Convert training texts to sequences\n",
    "X_val = torch.tensor([text_to_sequence(text) for text in val_texts]) # Convert validation texts to sequences\n",
    "y_train = torch.tensor(train_labels.tolist()) # Convert training labels to tensor\n",
    "y_val = torch.tensor(val_labels.tolist()) # Convert validation labels to tensor\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train) # Create TensorDataset for training data\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val) # Create TensorDataset for validation data\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) # Create DataLoader for training data\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE) # Create DataLoader for validation data\n",
    "\n",
    "# ========== MODEL ========== #\n",
    "class BiLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTMWithAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, _ = self.lstm(embedded)\n",
    "        attn_weights = torch.softmax(self.attention(outputs).squeeze(-1), dim=1)\n",
    "        context = torch.sum(outputs * attn_weights.unsqueeze(-1), dim=1)\n",
    "        return self.fc(context)\n",
    "\n",
    "model = BiLSTMWithAttention(len(vocab_dict), embed_dim=EMBED_DIM, hidden_dim=HIDDEN_DIM, output_dim=len(le.classes_)).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ========== TRAINING LOOP ========== #\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    print(classification_report(all_labels, all_preds, target_names=le.classes_))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    loss = train(model, train_loader)\n",
    "    print(f\"Train Loss: {loss:.4f}\")\n",
    "    evaluate(model, val_loader)\n",
    "\n",
    "# Save model and vocab\n",
    "torch.save(model.state_dict(), \"bilstm_model.pt\")\n",
    "with open(\"vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab_dict, f)\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb56233-a9c8-4d51-90a2-e175e119b273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11d8b2-66b8-4baf-8488-34ac4b8f88a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
